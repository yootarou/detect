import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from efficientnet_pytorch import EfficientNet


# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
batch_size = 16
epochs = 50
patience = 5
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_name = 'efficientnet-b0'

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã‚‚ã“ã“ã«å«ã‚ã‚‹
# =====================
# ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¯ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼‰
# =====================
train_transforms = transforms.Compose([
    transforms.Resize(256),
    transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),
    transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225]),
])

val_transforms = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225]),
])

# =====================
# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
# =====================
train_dir = "/Users/suenatiyoutarou/Library/CloudStorage/OneDrive-å€‹äººç”¨/dataset/train"
val_dir   = "/Users/suenatiyoutarou/Library/CloudStorage/OneDrive-å€‹äººç”¨/dataset/valid"

train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)
val_dataset   = datasets.ImageFolder(val_dir, transform=val_transforms)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

# =====================
# ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ï¼ˆDropoutè¿½åŠ ï¼‰
# =====================
model = EfficientNet.from_pretrained(model_name)
num_ftrs = model._fc.in_features
model._fc = nn.Sequential(
    nn.Dropout(p=0.5),
    nn.Linear(num_ftrs, 2)
)
model = model.to(device)

# =====================
# æå¤±é–¢æ•°ãƒ»æœ€é©åŒ–
# =====================
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)

# =====================
# EarlyStoppingç”¨å¤‰æ•°
# =====================
best_val_acc = 0.0
counter = 0

# =====================
# å­¦ç¿’ãƒ«ãƒ¼ãƒ—
# =====================
for epoch in range(epochs):
    # ------- è¨“ç·´ -------
    model.train()
    running_loss, correct = 0.0, 0
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * inputs.size(0)
        preds = outputs.argmax(1)
        correct += (preds == labels).sum().item()
    epoch_loss = running_loss / len(train_dataset)
    epoch_acc = correct / len(train_dataset)

    # ------- æ¤œè¨¼ -------
    model.eval()
    val_loss, val_correct = 0.0, 0
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item() * inputs.size(0)
            preds = outputs.argmax(1)
            val_correct += (preds == labels).sum().item()
    val_loss /= len(val_dataset)
    val_acc = val_correct / len(val_dataset)

    # å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©æ›´æ–°
    scheduler.step(val_acc)

    print(f"Epoch {epoch+1}/{epochs} "
          f"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f} "
          f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}")
    # EarlyStoppingåˆ¤å®š
    if val_acc > best_val_acc:
        best_val_acc = val_acc
        counter = 0
        torch.save(model.state_dict(), "best_model.pth")  # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ä¿å­˜
    else:
        counter += 1
        if counter >= patience:
            print(f"ğŸ›‘ EarlyStopping: {patience} epochs with no improvement.")
            break
print(f"âœ… å­¦ç¿’çµ‚äº†ã€‚ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã¯ best_model.pth ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")